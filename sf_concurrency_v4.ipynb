{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a66e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import threading\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e4341d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9dc4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['ACCOUNT'] = \"ek38061\"\n",
    "os.environ['REGION'] = \"central-india.azure\"\n",
    "os.environ['USER'] = \"sohankotkar3\"\n",
    "os.environ['PASSWORD'] = \"Sohan321\"\n",
    "os.environ['ROLE'] = \"ACCOUNTADMIN\"\n",
    "os.environ['WAREHOUSE'] = \"WH_XSMALL\"\n",
    "os.environ['DATABASE'] = \"FIVEKASSETS\"\n",
    "os.environ['SCHEMA'] = \"PUBLIC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4d9f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = snowflake.connector.connect(\n",
    "    user = os.environ['USER'],\n",
    "    password = os.environ['PASSWORD'],\n",
    "    account = os.environ['ACCOUNT'],\n",
    "    region = os.environ['REGION'],\n",
    "    database = os.environ['DATABASE'],\n",
    "    warehouse = os.environ['WAREHOUSE'],\n",
    "    schema = os.environ['SCHEMA'],\n",
    "    role = os.environ['ROLE']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b608cd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 1 #Now Warehouse has only 1 cluster and it won't add any extra cluster when load increases.\n",
    "concurrent_queries = 441528"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337fbc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the maximum number of clusters available to the warehouse\n",
    "def set_max_clusters(i):\n",
    "    connection.cursor().execute(\n",
    "        'alter warehouse \"' + os.environ['WAREHOUSE'] +\n",
    "        '\" set min_cluster_count = 1 max_cluster_count = ' + str(i)\n",
    "    )\n",
    "    connection.cursor().execute(\n",
    "        'ALTER SESSION SET USE_CACHED_RESULT = FALSE'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cac297",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    'select id, time, isValid, dataStatus, nodeStatus, value from Fivekassets.PUBLIC.staticdata_big_tw3 where id = (SELECT id from Fivekasset.PUBLIC.distid where seq = %s )',\n",
    "    'select id, time, isValid, dataStatus, nodeStatus, value from Fivekassets.PUBLIC.staticdata_big_tw3 where id = (SELECT id from Fivekasset.PUBLIC.distid where seq = %s ) and time =\\'2018-05-10 13:45:46.000\\' ',\n",
    "    'select distinct fullData.* from Fivekassets.PUBLIC.staticdata_big_tw3 fullData inner join ( select id, min(time) as minMaxTime from ( select id, time from Fivekassets.PUBLIC.staticdata_big_tw3 where id = (SELECT id from Fivekasset.PUBLIC.distid where seq = %s ) and time >= \\'2018-02-19 13:34:55.000\\' and time <= \\'2021-11-03 11:05:10.000\\' ) as minimumData group by id ) as minMaxData on ( fullData.id = minMaxData.id and fullData.time = minMaxData.minMaxTime )',\n",
    "    'select distinct fullData.* from Fivekassets.PUBLIC.staticdata_big_tw3 fullData inner join ( select id, max(time) as minMaxTime from ( select id, time from Fivekassets.PUBLIC.staticdata_big_tw3 where id = (SELECT id from Fivekasset.PUBLIC.distid where seq = %s ) and time >= \\'2018-02-19 13:34:55.000\\' and time <= \\'2021-11-03 11:05:10.000\\' ) as minimumData group by id ) as minMaxData on ( fullData.id = minMaxData.id and fullData.time = minMaxData.minMaxTime )'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8901139",
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_results = []\n",
    "query_set_results = []\n",
    "\n",
    "class ConcurrentQuery (threading.Thread):\n",
    "    \n",
    "    def __init__(self, total, counter, clusters, seq):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.counter = counter\n",
    "        self.total = total\n",
    "        self.clusters = clusters\n",
    "        self.seq = seq\n",
    "\n",
    "    def run(self):\n",
    "        cur = connection.cursor()\n",
    "        query_number = 0\n",
    "        print(\"seq = \"+str(self.seq))\n",
    "        qs_start_ts = time.time()\n",
    "#        for seq in range(11,21):\n",
    "        for query in queries:\n",
    "            start_ts = time.time()\n",
    "            cur.execute(query, str(self.seq))\n",
    "            end_ts = time.time()\n",
    "            individual_results.append(\n",
    "                {\n",
    "                    'clusters': self.clusters,\n",
    "                    'total': self.total,\n",
    "                    'counter': self.counter,\n",
    "                    'query_number': query_number,\n",
    "                    'start_time': time.strftime('%Y-%m-%dT%H:%M:%S', time.localtime(start_ts)),\n",
    "                    'execution_time': end_ts - start_ts,\n",
    "                    'query_id': cur.sfqid\n",
    "                }\n",
    "            )\n",
    "            query_number = query_number + 1\n",
    "            self.seq = self.seq + 1\n",
    "            time.sleep(seq%5) # Here we are mimicing real world scenario where we expect some gap between 2 consecutive queries.\n",
    "        qs_end_ts = time.time()\n",
    "        query_set_results.append(\n",
    "            {\n",
    "                'clusters': self.clusters,\n",
    "                'total': self.total,\n",
    "                'counter': self.counter,\n",
    "                'start_time': time.strftime('%Y-%m-%dT%H:%M:%S', time.localtime(qs_start_ts)),\n",
    "                'execution_time': qs_end_ts - qs_start_ts,\n",
    "                'query_id': cur.sfqid\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8275c472",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_max_clusters(num_clusters)\n",
    "\n",
    "time.sleep(10) # it takes a bit of time for a cluster to spin up\n",
    "\n",
    "print(time.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "threads = []\n",
    "incre = len(queries)\n",
    "seq = 1\n",
    "\n",
    "for query_num in range(0, concurrent_queries):\n",
    "    thread = ConcurrentQuery(concurrent_queries, query_num, num_clusters, seq)\n",
    "    threads.append(thread)\n",
    "    seq = seq + incre\n",
    "print(\"Final seq = \"+str(seq))\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "print(time.strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b7fd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.DataFrame(individual_results)\n",
    "df.to_csv('concurrency_test_result3_individual_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567f7222",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pandas.DataFrame(query_set_results)\n",
    "df1.to_csv('concurrency_test_result3_queryset_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b7449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time.strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2ab64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9d62ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"select id, time, isValid, dataStatus, nodeStatus, value from Fivekassets.PUBLIC.staticdata_azure where id = (SELECT id from Fivekasset.PUBLIC.distid where seq = %s )\", str(19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd60d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbe23fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5adb824",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(q%5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d8837f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
